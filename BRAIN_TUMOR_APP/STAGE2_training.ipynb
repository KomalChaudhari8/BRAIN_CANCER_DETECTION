{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a82019",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb27cc92",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac40cf50",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd, tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "IMG_SIZE = 300\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "BASE_DIR = \"/content/drive/MyDrive/BrainTumorDetection\"\n",
    "\n",
    "LOG_DIR   = f\"{BASE_DIR}/Logs\"\n",
    "MODEL_DIR = f\"{BASE_DIR}/Models\"\n",
    "\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d6aea1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class FocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, gamma=2.0, alpha=0.25,\n",
    "                 reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE,\n",
    "                 name=\"focal_loss\"):\n",
    "        super().__init__(reduction=reduction, name=name)\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "        ce = -y_true * tf.math.log(y_pred)\n",
    "        fl = self.alpha * tf.pow(1 - y_pred, self.gamma) * ce\n",
    "        return tf.reduce_mean(tf.reduce_sum(fl, axis=1))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"gamma\": self.gamma,\n",
    "            \"alpha\": self.alpha\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0a1edb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def attention_block(x):\n",
    "    gap = layers.GlobalAveragePooling2D()(x)\n",
    "    dense = layers.Dense(x.shape[-1]//8, activation=\"relu\")(gap)\n",
    "    scale = layers.Dense(x.shape[-1], activation=\"sigmoid\")(dense)\n",
    "    scale = layers.Reshape((1,1,x.shape[-1]))(scale)\n",
    "    return layers.Multiply()([x, scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c12b02",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def last_epoch(csv_path):\n",
    "    # File does not exist\n",
    "    if not os.path.exists(csv_path):\n",
    "        return 0\n",
    "\n",
    "    # File exists but is empty\n",
    "    if os.path.getsize(csv_path) == 0:\n",
    "        return 0\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        return len(df)\n",
    "    except Exception:\n",
    "        # Covers EmptyDataError or corrupted CSV\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb6f817",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "\n",
    "class Stage2MRIGenerator(Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir,\n",
    "        batch_size=16,\n",
    "        img_size=(300, 300),\n",
    "        augment=False,\n",
    "        shuffle=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.samples = []\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # class folders: glioma, meningioma, pituitary\n",
    "        self.classes = sorted([\n",
    "            d for d in os.listdir(root_dir)\n",
    "            if os.path.isdir(os.path.join(root_dir, d))\n",
    "        ])\n",
    "        self.class_map = {c: i for i, c in enumerate(self.classes)}\n",
    "\n",
    "        for cls in self.classes:\n",
    "            cls_dir = os.path.join(root_dir, cls)\n",
    "            for img in os.listdir(cls_dir):\n",
    "                if img.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                    self.samples.append(\n",
    "                        (os.path.join(cls_dir, img), self.class_map[cls])\n",
    "                    )\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.samples) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch = self.samples[\n",
    "            idx * self.batch_size : (idx + 1) * self.batch_size\n",
    "        ]\n",
    "\n",
    "        X, y = [], []\n",
    "\n",
    "        for path, label in batch:\n",
    "            img = load_img(path, target_size=self.img_size)\n",
    "            img = img_to_array(img)\n",
    "\n",
    "            # EfficientNet preprocessing\n",
    "            img = preprocess_input(img)\n",
    "\n",
    "            # ðŸŽ¯ Class-specific augmentation\n",
    "            if self.augment:\n",
    "                # Glioma = stronger augmentation\n",
    "                if self.classes[label] == \"glioma\":\n",
    "                    if np.random.rand() > 0.3:\n",
    "                        img = tf.image.flip_left_right(img)\n",
    "                    if np.random.rand() > 0.3:\n",
    "                        img = tf.image.random_brightness(img, 0.15)\n",
    "                else:\n",
    "                    if np.random.rand() > 0.6:\n",
    "                        img = tf.image.flip_left_right(img)\n",
    "\n",
    "            X.append(img)\n",
    "            y.append(label)\n",
    "\n",
    "        return (\n",
    "            np.array(X, dtype=np.float32),\n",
    "            tf.keras.utils.to_categorical(y, len(self.classes))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f07559",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_stage2_model(n):\n",
    "    base = EfficientNetB3(weights=\"imagenet\", include_top=False,\n",
    "                          input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    base.trainable = False\n",
    "\n",
    "    x = attention_block(base.output)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    out = layers.Dense(n, activation=\"softmax\")(x)\n",
    "\n",
    "    return models.Model(base.input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faeea61",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(STAGE2_LOG):\n",
    "    with open(STAGE2_LOG, \"w\") as f:\n",
    "        f.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05191f6c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "initial_epoch = last_epoch(STAGE2_LOG)\n",
    "print(\"Stage-2 resume from:\", initial_epoch)\n",
    "\n",
    "if os.path.exists(STAGE2_BEST):\n",
    "    model2 = tf.keras.models.load_model(\n",
    "        STAGE2_BEST,\n",
    "        custom_objects={\"FocalLoss\": FocalLoss, \"attention_block\": attention_block}\n",
    "    )\n",
    "else:\n",
    "    model2 = build_stage2_model(3)\n",
    "\n",
    "model2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=FocalLoss(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "callbacks2 = [\n",
    "    ModelCheckpoint(STAGE2_BEST, save_best_only=True, monitor=\"val_loss\"),\n",
    "    CSVLogger(STAGE2_LOG, append=True),\n",
    "    ReduceLROnPlateau(patience=3, factor=0.3),\n",
    "    EarlyStopping(patience=6, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "model2.fit(\n",
    "    Stage2MRIGenerator(STAGE2_TRAIN, augment=True),\n",
    "    validation_data=Stage2MRIGenerator(STAGE2_VAL),\n",
    "    epochs=40,\n",
    "    initial_epoch=initial_epoch,\n",
    "    callbacks=callbacks2\n",
    ")\n",
    "\n",
    "model2.save(STAGE2_FINAL)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V5E1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
